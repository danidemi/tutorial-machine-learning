{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I SVC sono una classe di algoritmi supervisionati che possono essere utilizzati sia per problemi di regressione sia per problemi di classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "#Creazione di 100 punti divisi in due classi\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c definisce i colori: A sequence of n numbers to be mapped to colors using cmap;\n",
    "# s definisce la grandezza dei punti;\n",
    "# cmap definisce la mappa di colori da utilizzare;\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supponiamo di avere dei dati strutturati in questo modo: o rossi o blu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosa possiamo dedurre da questo grafico?\n",
    "\n",
    "1. Supponi di avere un punto di coordinate (8,-2), lo classificheresti come azzurro o come rosso?\n",
    "2. Supponi di avere un punto di coordinate (7,-6), lo classificheresti come azzurro o come rosso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando il grafico possiamo dire che i dati sembrano essere *linearmente separabili* cioè \n",
    "possiamo tracciare una retta che divide il piano in due parti:\n",
    "da una parte i *rossi* dall'altra i *blu*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"./boundary.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOMANDA:\n",
    "1. Quante sono le rette che dividono i punti?\n",
    "2. Come scegliamo la *migliore*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'idea che sta alla base degli algoritmi di SVM è di trovare quella retta che massimizza la distanza dagli argini!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per definire la retta che divide le due classi, l'SVM utilizza i punti che stanno ai bordi, chiamati **support vectors**. Il numero di punti che vengono utilizzati per definire gli argini dipende da come impostiamo il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"./supportVector.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se imponiamo che tutti i punti debbano stare fuori dai margini allora stiamo facendo una **hard margin classification**:\n",
    "lati negativi:\n",
    "1. Funziona solamente se i dati sono lineramente separabili;\n",
    "2. E' molto sensibile agli outliers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"./svm_with_c1.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per avere un modello più flessibile si cerca di tenere i margini più ampi possibili e minimizzare i punti che finiscono nei bordi: **soft margin classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"./svm_with_c0.1.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo il fit del modello: più C è alto più ci avviciniamo ad un hard margin classification\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "clf.fit(X, y)\n",
    "#clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta fatto il fit del modello, possiamo farci restituire i support_vectors, all'aumentare di C il numero di support_vectors_ aumenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "#Disegna i support vectors del modello:\n",
    "\n",
    "plt.scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.decision_function([[7,-6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# Otteniamo gli estremi dei due assi:\n",
    "ax = plt.gca() #Get axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Griglia di punti\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# Fai il plot dei punti che hanno decision_function = -1, 0, 1\n",
    "#https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.contour.html\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1],  alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# plot support vectors\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'iperparametro C\n",
    "\n",
    "L'iperparametro che ci permette di regolarizzare il modello è C, se non specificato assume di default il valore 1. Se ci accorgiamo che il modello sta facendo overfitting allora si può regolarizzare diminuendo il valore di C. Al diminuire di C l'ampiezza degli argini e il numero di support vectors aumenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESERCIZIO\n",
    "\n",
    "Utilizzando il metodo make_blobs genera dei nuovi dati utilizzando il parametro cluster_std = [0.5, 2.5] e disegna il grafico della decision function per i valori -1,0,1 (come negli esempi precedenti), come variano i margini al crescere di cluster_std?\n",
    "Genera la confusion_matrix per tutti i casi;\n",
    "\n",
    "[soluzione](./soluzione/cluster_std.ipynb).\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dati non linearmente separabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "x = []\n",
    "y = []\n",
    "for i in range(0,50):\n",
    "    x += [[random.uniform(-1,1),random.uniform(-1,1)]]\n",
    "    y += [0]\n",
    "for i in range(50,100):\n",
    "    r_i = float(random.uniform(2,2.5))\n",
    "    x_i = float(random.uniform(-3,3))\n",
    "    y_i_2 = r_i**2 - x_i**2\n",
    "    if y_i_2>=0:\n",
    "        y_i = random.choice([-1,1])*math.sqrt(y_i_2)\n",
    "        x += [[x_i,y_i]]\n",
    "        y += [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(x).reshape(len(x),2)\n",
    "y = np.asarray(y).reshape(len(y),1).ravel()\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y,cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly', degree=2, C=5 )\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# Otteniamo gli estremi dei due assi:\n",
    "ax = plt.gca() #Get axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Griglia di punti\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# Fai il plot dei punti che hanno decision_function = -1, 0, 1\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# plot support vectors\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Features\n",
    "### Gaussian Radial Basis Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nell'esempio de MNIST abbiano utilizzato la classe SVC senza specificare nessun kernel...quale kernel ha usato???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se non viene specificato un kernel allora di default viene usato il Gaussian Radial Basis Function (rbf).\n",
    "Questo kernel si basa sul metodo delle similarity features, cioè aggiunge delle features in modo tale da separare linearmente i dati.\n",
    "Supponiamo di avere due funzioni definite da due landmark (nel disegno i due landmark sono i punti -2 e 1):\n",
    "la prima è una Gaussiana centrata in -2; la seconda è una Gaussiana centrata in 1\n",
    "Ora per ogni punto del dataset viene calcolato il valore del punto rispetto alle due gaussiane:\n",
    "* -2 -> (1 , 0.01)\n",
    "* -4 -> (0.25 , 0)\n",
    "\n",
    "una volta che i dati sono stati trasformati la feature X_1 non si considera più e si considerano invece le feature X_2 e X_3, rispetto a queste due features i dati risultano essere linearmente separabili!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"./gaussianRBF.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOMANDA:\n",
    "    1. il punto 4 del grafico di sinistra in quale punto viene mappato nel grafico a destra?\n",
    "    2. il punto 1 del grafico di sinistra in quale punto viene mappato nel grafico a destra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "#Creazione di 100 punti divisi in due classi\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=6, cluster_std = 2)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y,cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default: kernel='rbf'\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# Otteniamo gli estremi dei due assi:\n",
    "ax = plt.gca() #Get axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Griglia di punti\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# Fai il plot dei punti che hanno decision_function = -1, 0, 1\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# plot support vectors\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando si usa come classificatore l'SVC con kernel = 'rbf' per regolarizzare il modello si può giocare sia su C che su gamma. Gamma è il parametro che fa variare l'ampiezza della curva gaussiana\n",
    "1. se gamma è alto allora le gaussiane saranno schiacciate;\n",
    "2. se gamma è piccolo allora le code saranno più ampie;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESERCIZIO:\n",
    "Genera dei dati usando make_blobs(n_samples=100, centers=2, random_state=6, cluster_std = 2, n_features = 2):\n",
    "\n",
    "fai il training del SVC usando un kernel rbf e scegliendo gamma = [1, 10, 100] e C = 1\n",
    "\n",
    "[soluzione](./soluzione/kernelRBF.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
